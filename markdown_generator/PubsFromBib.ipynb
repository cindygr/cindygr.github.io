{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T23:05:32.352517Z",
     "start_time": "2024-11-09T23:05:30.085766Z"
    }
   },
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pybtex\n",
    "\n",
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pybtex\r\n",
      "  Downloading pybtex-0.24.0-py2.py3-none-any.whl.metadata (2.0 kB)\r\n",
      "Requirement already satisfied: PyYAML>=3.01 in /opt/anaconda3/lib/python3.12/site-packages (from pybtex) (6.0.1)\r\n",
      "Collecting latexcodec>=1.0.4 (from pybtex)\r\n",
      "  Downloading latexcodec-3.0.0-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from pybtex) (1.16.0)\r\n",
      "Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m561.4/561.4 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading latexcodec-3.0.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: latexcodec, pybtex\r\n",
      "Successfully installed latexcodec-3.0.0 pybtex-0.24.0\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T23:57:25.758277Z",
     "start_time": "2024-11-10T23:57:25.754088Z"
    }
   },
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"\"\"\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"journal.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\"\"\"\n",
    "    \"journal\":{\n",
    "        \"file\": \"new_papers2006.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:30:22.780105Z",
     "start_time": "2024-11-10T02:30:22.777033Z"
    }
   },
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T23:57:30.444762Z",
     "start_time": "2024-11-10T23:57:30.427100Z"
    }
   },
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            #url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            #url_slug = url_slug.replace(\"--\",\"-\")\n",
    "            url_slug = bib_id\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            #citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            # citation = citation + \" \" + html_escape(venue)\n",
    "            # citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\ncategory: conferences\"\"\"\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "\n",
    "            \"\"\"            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "            \"\"\"\n",
    "\n",
    "            md += \"\"\"\\npaperurl: 'http://cindygr.github.io/files/\"\"\" + bib_id + \"\"\".pdf'\\n\"\"\"\n",
    "            \n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            #  else:\n",
    "            #      md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCESSFULLY PARSED arx2022rp: \" An autonomous robot for pruning modern, planar fruit trees  \"\n",
      "SUCESSFULLY PARSED icra2022brh: \" Benchmarking a Robot Hand{'}s Ability to Translate Objects U ... \"\n",
      "SUCESSFULLY PARSED ifac2022cde: \" Canopy Density Estimation of Apple Trees  \"\n",
      "SUCESSFULLY PARSED icra2022hrt: \" Effects of Interfaces on Human-Robot Trust: Specifying and V ... \"\n",
      "SUCESSFULLY PARSED arx2022gr: \" Measuring a Robot Hand{'}s Graspable Region using Power and  ... \"\n",
      "SUCESSFULLY PARSED iros2022ofbs: \" Optical flow-based branch segmentation for complex orchard e ... \"\n",
      "SUCESSFULLY PARSED arx2022ofbs: \" Optical flow-based branch segmentation for complex orchard e ... \"\n",
      "SUCESSFULLY PARSED arx2022pl: \" Optimization-Based Mechanical Perception for Peduncle Locali ... \"\n",
      "SUCESSFULLY PARSED vc2022sc: \" Perceptually grounded quantification of 2D shape complexity  \"\n",
      "SUCESSFULLY PARSED icra2022pftp: \" Precision fruit tree pruning using a learned hybrid vision/i ... \"\n",
      "SUCESSFULLY PARSED iros2022pfs: \" Predicting fruit-pick success using a grasp classifier train ... \"\n",
      "SUCESSFULLY PARSED ce2022skel: \" Semantics-guided skeletonization of upright fruiting offshoo ... \"\n",
      "SUCESSFULLY PARSED hf2021cbtt: \" Developing and Validating a Computer-Based Training Tool for ... \"\n",
      "SUCESSFULLY PARSED arx2021hrt: \" Effects of interfaces on human-robot trust: Specifying and v ... \"\n",
      "SUCESSFULLY PARSED arx2021nos: \" Grasping benchmarks: Normalizing for object size \\&amp; appr ... \"\n",
      "SUCESSFULLY PARSED icra2021igc: \" Improving Grasp Classification through Spatial Metrics Avail ... \"\n",
      "SUCESSFULLY PARSED thri2021mm: \" Mental Models of a Mobile Shoe Rack  \"\n",
      "SUCESSFULLY PARSED arx2021pftp: \" Precision fruit tree pruning using a learned hybrid vision/i ... \"\n",
      "SUCESSFULLY PARSED arx2021rp: \" Semantics-guided skeletonization of sweet cherry trees for r ... \"\n",
      "SUCESSFULLY PARSED icra2021ifp: \" Towards Intelligent Fruit Picking with In-hand Sensing  \"\n",
      "SUCESSFULLY PARSED arx20203dv: \" Analyzing 3D volume segmentation by low-level perceptual cue ... \"\n",
      "SUCESSFULLY PARSED ral2020bp: \" Benchmarking protocol for grasp planning algorithms  \"\n",
      "SUCESSFULLY PARSED arx2020itt: \" Developing and Validating An Interactive Training Tool for I ... \"\n",
      "SUCESSFULLY PARSED asme2020vdb: \" Vision-based precision deburring and edge breaking process q ... \"\n",
      "SUCESSFULLY PARSED exp2019acb: \" Aesthetics of Curvature Bases for Sketches  \"\n",
      "SUCESSFULLY PARSED arx2019fe: \" Framing effects on privacy concerns about a home telepresenc ... \"\n",
      "SUCESSFULLY PARSED iros2019ncg: \" Near-contact grasping strategies from awkward poses: When si ... \"\n",
      "SUCESSFULLY PARSED ln2019pc: \" Privacy Concerns in Robot Teleoperation: Does Personality In ... \"\n",
      "SUCESSFULLY PARSED ln2019puc: \" Privacy, Utility, and Cognitive Load in Remote Presence Syst ... \"\n",
      "SUCESSFULLY PARSED bio2018bio: \" Biodiversifying bioinspiration  \"\n",
      "SUCESSFULLY PARSED awm20182ds: \" Exploring 2D shape complexity  \"\n",
      "SUCESSFULLY PARSED ubi2018gd: \" Identifying Gender Differences in Information Processing Sty ... \"\n",
      "SUCESSFULLY PARSED biomech2018viz: \" Visualization of chicken embryo heart motion  \"\n",
      "SUCESSFULLY PARSED roman2017fg: \" A focus group study of privacy concerns about telepresence r ... \"\n",
      "SUCESSFULLY PARSED arx2017tpc: \" A taxonomy of privacy constructs for privacy-sensitive robot ... \"\n",
      "SUCESSFULLY PARSED hri2017ptp: \" Privacy and telepresence robotics: What do non-scientists th ... \"\n",
      "SUCESSFULLY PARSED hri2017puc: \" Privacy, utility, and cognitive load in remote presence syst ... \"\n",
      "SUCESSFULLY PARSED hri2017psr: \" Privacy-sensitive robotics  \"\n",
      "SUCESSFULLY PARSED iros2017eb: \" Using an environmentally benign and degradable elastomer in  ... \"\n",
      "SUCESSFULLY PARSED jbioGrimm2016gb: \" A Geodesics-Based Surface Parameterization to Assess Aneurys ... \"\n",
      "SUCESSFULLY PARSED apgvGrimm2016emm: \" How experts{'} mental model affects 3D image segmentation  \"\n",
      "SUCESSFULLY PARSED biomec2018viz: \" Visualization of chicken embryo heart motion  \"\n",
      "SUCESSFULLY PARSED cg2016tb: \" Template-based surface reconstruction from cross-sections  \"\n",
      "SUCESSFULLY PARSED law2017are: \" Averting Robot Eyes  \"\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T02:52:04.456345Z",
     "start_time": "2024-11-10T02:52:04.453390Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
